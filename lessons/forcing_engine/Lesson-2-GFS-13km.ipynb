{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - GFS 13km Processing\n",
    "## Overview\n",
    "In this lesson, we will be running the Python forcing engine code on basin 01447720. We will be processing GFS 13km gaussian grid data to the modeling domain. In this example, no downscaling is taking place.\n",
    "\n",
    "### Requirements\n",
    "The easiest and recommended way to run these lessons is via the [wrfhydro/forcing-engine](https://hub.docker.com/r/wrfhydro/forcing-engine/) Docker container, which has all software dependencies and data pre-installed.\n",
    "\n",
    "* Docker = v.18.09.2 \n",
    "* Web browser (Google Chrome recommended)\n",
    "\n",
    "### Where to get help and/or post issues\n",
    "If you have general questions about Docker, there are ample online resources including the excellent Docker documentation at https://docs.docker.com/.\n",
    "\n",
    "The best place to ask questions or post issues with these lessons is via our online contact form at https://ral.ucar.edu/projects/wrf_hydro/contact.\n",
    "\n",
    "\n",
    "## How to run\n",
    "Make sure you have Docker installed and that it can access your localhost ports. Most out-of-the-box Docker installations accepting all defaults will have this configuration.\n",
    "\n",
    "**Step 1: Open a terminal or PowerShell session**\n",
    "\n",
    "**Step 2: Pull the wrfhydro/forcing-engine Docker container**\n",
    "Each training container is specific to a release version of the NWM source code, which can be found at https://github.com/NCAR/wrf_hydro_nwm_public/releases.\n",
    "\n",
    "Issue the following command in your terminal to pull a specific version of the training corresponding to your code release version.\n",
    "\n",
    "`docker pull wrfhydro/forcing-engine:latest`\n",
    "\n",
    "**Step 3: Start the training container**\n",
    "Issue the following command in your terminal session to start the training Docker container.\n",
    "\n",
    "`docker run --name forcing-engine -p 8888:8888 -it wrfhydro/forcing-engine:latest`\n",
    "\n",
    "The container will start and perform a number of actions before starting the training. \n",
    "\n",
    "**Note: If you have already started the training once you will need to remove the previous container using the command\n",
    "\n",
    "`docker rm forcing-engine`\n",
    "\n",
    "**Step 4: Connect to Jupyter Notebook server using your browser**\n",
    "\n",
    "At the end of the container startup process an address and password will be printed to the terminal. The address and password are used to connect to the container Jupyter Notebook server. All training lesson notebooks in this container are in the `/home/docker/wrf-hydro-training/lessons` directory and can be opened in your browser using Jupyter.\n",
    "\n",
    "## What is included\n",
    "\n",
    "* The Python forcing engine code. This code is still in Beta testing/development.\n",
    "* Future code will be updated on the forcing engine repo, and Docker images will be updated accordingly. \n",
    "* Input GRIB2 forcing files (GFS) that are ingested into the FE. Note these files have been subsetted to the Pennsylvania region to conserve space. \n",
    "* Domain files necessary to process input forcings to the domain. \n",
    "* Pre-installed ESMF that was built against MPICH. This includes the Python ESMPy wrapper. \n",
    "* Forcing engine training lessons as Jupyter Notebooks\n",
    "* Jupyter Notebook server.\n",
    "\n",
    "**Note: Port forwarding is setup with the `-p 8888:8888` argument, which maps your localhost port to the container port. If you already have something running on port 8888 on your localhost you will need to change this number**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Input Forcings\n",
    "We will first examine the input forcing GRIB2 files needed for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Forcing_Inputs\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Forcing_Inputs/GFS_13km\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Forcing_Inputs/GFS_13km/gfs.2019022412\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Forcing_Inputs/GFS_13km/gfs.2019022412\n",
    "wgrib2 -V -match \":(PRATE):\" gfs.t12z.sfluxgrbf24.grib2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** - These GRIB2 files were initially subsetted to a lat/lon bounding box using wgrib2's nifty -small_grib flag. It's a great way to slim your GRIB2 inputs to a more manageable size when working on regional/local domains. Documentation on this can be found at - https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/small_grib.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation of Python Code\n",
    "We will first begin by taking a high-level view of the directory structure above the code that contains our inputs and outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing\n",
    "ls DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/WrfHydroForcing\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** - The forcing engine is called by genForcing.py for all instances of the processing. No need for multiple calls to different programs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/WrfHydroForcing/core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcing Engine Configuration File \n",
    "We will inspect the configuration file in detail, and outline the options for this specific exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "ls /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Config/template_forcing_engine_AnA.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of the Forcing Engine\n",
    "We will now execute the forcing engine, providing the configuration file just discussed. For this exercise, we will use two CPU cores in our MPI execution. Note that in larger domains with more data, you will want to use more CPUs to reduce the memory usage on a given core. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/WrfHydroForcing\n",
    "mpiexec -np 2 python genForcing.py /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Config/template_forcing_engine_Medium.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection of Outputs\n",
    "The top level output directory contains a subdirectory for each \"cycle's\" worth of forcing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Output/Medium_Config\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Output/Medium_Config/201902241200\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this directory, we see two additional files to the output files:\n",
    "    1) A LOG file that contains messaging about the status of the forcing processing.\n",
    "    2) A COMPLETE flag indicating processing for this cycle is complete. \n",
    "Let's inspect the LOG file...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Output/Medium_Config/201902241200\n",
    "cat LOG*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect one of the output forcing files. You will note the comprehensive level of geospatial metadata included. If the spatial metadata file is not specified in the configuration file. You will see much less geospatial information and the files most likely will not display correctly in GIS applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/docker/wrf-hydro-training/forcing_engine/Pocono_Forcing/Output/Medium_Config/201902241200\n",
    "ncdump -h 201902241300.LDASIN_DOMAIN1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© UCAR 2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
