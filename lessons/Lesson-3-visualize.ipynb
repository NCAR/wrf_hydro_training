{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://repository-images.githubusercontent.com/121802384/c355bb80-7d42-11e9-9e0e-4729609f9fbc' alt='WRF-Hydro Logo' width=\"15%\"/>\n",
    "\n",
    "# Lesson 3 - Working with WRF-Hydro inputs and output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "We will **briefly** discuss working with some of the WRF-Hydro input and output (IO) files. The IO files for WRF-Hydro generally are standard netCDF4 files, and there are many way to work with these data. In this lesson we simply cover a few Python libraries and commands that will be needed for later lessons in this tutorial. This is by no means a comprehensive guide to working with netCDF files. \n",
    "\n",
    "More information on working with netCDF files can be found on the Unidata website at https://www.unidata.ucar.edu/software/netcdf/. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to our Python environment and libraries\n",
    "We are using Python 3 for all exercises in this tutorial. There are also a number of tools developed in R that have similar capabilities, but we have chosen Python here for its ease of use and strong netCDF4 and geospatial processing support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "We are using the Miniconda distribution of Python 3 with the Python libraries listed below and their dependencies. Miniconda is a stripped down version of Anaconda, a Python distribution for scientific computing. You can obtain Miniconda from the Continuum Analytics website at https://conda.io/miniconda.html.\n",
    "\n",
    "There are many resources for learning more about miniconda, conda, and Python. Answers to just about any question can be found with a little searching on either Google or Stack Overflow.\n",
    "\n",
    "Below are the libraries we will be using. These libraries have been installed for you if you are running this tutorial in the [wrfhydro/training](https://hub.docker.com/r/wrfhydro/training/) Docker container. Otherwise, you will need to install miniconda and the required python libraries if running on your own system.\n",
    "\n",
    "**NOTE: The libraries listed below are only the required Python libraries. These Python libraries also require a number of system libraries that you may or may not need to install on your own system. Notably, you WILL need the NETCDF4 system library**\n",
    "\n",
    "**Required Python libraries:** \n",
    "\n",
    "**xarray:** xarray is an open-source project for working with self-describing Common Data Model scientific datasets, primarily in netCDF4 format. It eases many of the pain-points in loading, manipulating, and plotting multidimensional arrays. xarray is well documented and you can learn more by reading their documentation at https://xarray.pydata.org/en/stable/ or https://github.com/pydata/xarray.\n",
    "\n",
    "**netCDF4:** Library for reading and writing netCDF files. This is a required dependency for xarray if you will be using xarray with netCDF4 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray datasets\n",
    "Below is a brief list of the Python commands we will be running, virtually all of the commands are from the xarray package, indicated by a `xr.` prefix preceding the command.\n",
    "\n",
    "`xr.open_dataset('path-to-netcdf-file')`: Open a single netCDF file in xarray. \n",
    "\n",
    "**Note: This command only opens the netCDF file and reads header information, it does not load any of the data payload into memory** This is a handy feature of netCDF4 and xarray that allows for viewing basic information about very large netCDF files without loading into memory.\n",
    "\n",
    "`xr.open_mfdataset(list-of-netcdf-files or 'path-to-netcdf-directory', combine=’by_coords’)`: Similar to `xr.open_dataset`, `xr.open_mfdataset` opens multiple netCDF files as a single dataset, concatenating them along a common dimension(s). \n",
    "\n",
    "After we have opened the datasets there are a few more methods we will use on these datasets. \n",
    "\n",
    "`my_dataset = xr.open_dataset('path-to-netcdf-file')`\n",
    "\n",
    "`my_dataset.info()`: Print information about the netCDF file, similar to `ncdump` command line utility.\n",
    "\n",
    "`my_dataset.load()`: Load the netCDF4 data payload into memory\n",
    "\n",
    "`my_dataset.myvariable`: Access a variable named `myvariable` from the dataset.\n",
    "\n",
    "`my_dataset.myvariable.plot()`: Plot the variable my variable. Xarray will attempt to guess the axes, and in the case of spatial or timeseries data with only 1 dimension it typically does a good job. However, you may need to specify this manually if not.\n",
    "\n",
    "There is **MUCH** more you can do with `xarray`, but that covers the basic commands we will use in this training.\n",
    "\n",
    "In the next section we will go over a couple of basic examples of plotting some of the outputs from our `~/wrf-hydro-training/output/lesson2/run_gridded_default` simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "### 2D spatial with no temporal component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GEOGRID\n",
    "We will start with plotting a couple of variables from our geogrid file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls ~/wrf-hydro-training/output/lesson2/run_nwm_default/DOMAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "#### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import xarray and turn on fancy HTML representations of datasets\n",
    "import xarray as xr\n",
    "import glob\n",
    "xr.set_options(display_style=\"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**Open the geogrid dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "geogrid = xr.open_dataset('~/wrf-hydro-training/output/lesson2/run_nwm_default/DOMAIN/geo_em.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**Print some info about the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "geogrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**Plot the HGT_M variable, the topographic height in meters for each grid cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "geogrid.HGT_M.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**Plot the LU_INDEX variable, the dominant land-use class index for each grid cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "geogrid.LU_INDEX.plot(cmap=\"tab20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the SCT_DOM variable, the dominant soil type for each grid cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geogrid.SCT_DOM.plot(cmap=\"tab20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do you know what these values mean? You can check the parameter tables that come with the code to check lookup values. For example, the MPTABLE.TBL file lists the land cover categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat ~/wrf-hydro-training/output/lesson2/run_nwm_default/MPTABLE.TBL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SOILPARM.TBL file lists the soil types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat ~/wrf-hydro-training/output/lesson2/run_nwm_default/SOILPARM.TBL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FULLDOM\n",
    "Next we will look at the high-resolution routing domain file, `Fulldom.nc`.\n",
    "\n",
    "**Open the Fulldom dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "fulldom = xr.open_dataset('~/wrf-hydro-training/output/lesson2/run_nwm_default/DOMAIN/Fulldom.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print some info about the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the TOPOGRAPHY variable, the high-resolution elevation layer**\n",
    "\n",
    "This is the layer that controls much of the terrain routing. You'll notice the higher resolution of this layer compared to the HGT_M field in the geogrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldom.TOPOGRAPHY.plot(cmap=\"gist_earth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the CHANNELGRID variable, the location of channel cells on the high-resolution routing grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldom.CHANNELGRID.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOIL_PROPERTIES\n",
    "Let's also take a look in the NoahMP 2D/3D parameter file, `soil_properties.nc`. This is actually a bit of a misnomer, as this file contains parameters related to vegetation, surface, and soil properties. Vegetation and surface properties are in 2D, while soil properties can also (theoretically) vary with depth and are therefore in 3D. All are on the LSM grid.\n",
    "\n",
    "**Open the soil_properties dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "soilprop = xr.open_dataset('~/wrf-hydro-training/output/lesson2/run_nwm_default/DOMAIN/soil_properties.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print some info about the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soilprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the soil porosity (smcmax)**\n",
    "\n",
    "Default parameters by soil texture class are mapped from the `SOILPARM.TBL` lookup table to the soil type layer in the geogrid (`SCT_DOM`) to create an initial distribution of porosity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soilprop.smcmax.sel(soil_layers_stag = 0).plot(vmin=0.4, vmax=0.6, cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the vegetation height (hvt)**\n",
    "\n",
    "Similarly, for default configurations, vegetation height values are pulled from `MPTABLE.TBL` and mapped via the `LU_INDEX` field in the geogrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soilprop.hvt.plot(cmap=\"YlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### 2D spatial with no temporal component\n",
    "Now we will plot a timeseries from multiple netcdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = '/home/docker/wrf-hydro-training/output/lesson2/run_nwm_default/*CHANOBS*'\n",
    "files = sorted(glob.glob(file_pattern))\n",
    "datasets = [xr.open_dataset(f) for f in files]\n",
    "chanobs = xr.concat(datasets, dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**Print some info about the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we have a time dimension of length 744 corresponding to the 744 hourly output files from our simulation `run_nwm_default`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**Plot a hydrograph for at the gauge location**\n",
    "\n",
    "In this example case, there is only one gauge in the domain that we will plot the streamflow for that location without any indexing. For more information on indexing and selecting data with xarray see the [xarray documentation](http://xarray.pydata.org/en/stable/) if the domain of your interest has multiple gauges in the domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanobs.streamflow.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up - moving toward running PEST++ and WRF-Hydro\n",
    "This concludes lesson 3. In the [next lesson](Lesson-4-single-model.ipynb) we will discuss how to run a single model simulation using PEST++.\n",
    "\n",
    "**IT IS BEST TO EITHER SHUTDOWN THIS LESSON OR CLOSE IT BEFORE PROCEEDING TO THE NEXT LESSON TO AVOID POSSIBLY EXCEEDING ALLOCATED MEMORY. Shutdown the lesson be either closing the browser tab for the lesson or selecting `Kernel -> Shut Down Kernel` in JupyterLab.**\n",
    "\n",
    "© UCAR 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "464px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
