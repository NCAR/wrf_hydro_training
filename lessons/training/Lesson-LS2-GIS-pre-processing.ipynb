{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Source GIS Pre-Processing Tutorial\n",
    "\n",
    "This notebook will rely on the WRF-Hydro GIS Pre-processing tools, found here:  \n",
    "* https://github.com/NCAR/wrf_hydro_gis_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Create domain boundary shapefile](#1.-Create-domain-boundary-shapefile)<br>\n",
    "2. [Build geotiff from geogrid file](#2.-Build-GeoTiff-raster-from-a-WPS-Geogrid-file)<br>\n",
    "3. [Build routing stack](#3.-Building-the-hydrologic-routing-grids,-aka-the-\"routing-stack\")<br>\n",
    "4. [Examine outputs of GIS pre-processor](#4.-Examine-outputs-of-GIS-pre-processor)\n",
    "5. [Vizualize the output grids](#5.-Vizualize-the-output-grids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, set file paths\n",
    "In this cell, Python variables are created that point to the file paths of the test-case data and an output directory is defined to store the data created by these tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import python core modules\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set root directory for GIS lesson\n",
    "gis_data_folder = \"/home/docker/GIS_Training\"\n",
    "\n",
    "# Change the directory to the GIS_Training directory and get current working directory\n",
    "os.chdir(gis_data_folder)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set paths to known input and output directories and files\n",
    "data_folder = os.path.join(cwd, 'Croton_Lambert')\n",
    "in_geogrid = os.path.join(data_folder, 'geo_em.d01.nc')\n",
    "output_folder = os.path.join(cwd, 'Outputs')\n",
    "\n",
    "# Clear any outputs from previous runs\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create domain boundary shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tool `Create_Domain_Boundary_Shapefile.py` takes a WRF (WPS) output file, aka \"Geogrid file\", and creates a polygon shapefile that defines the boundary of the domain as a single rectangular polygon in projected coordinates. The script will read metadata in the geogrid file and the output shapefile will be in the projection of the WRF domain. The unstaggered grid, or \"Mass\" grid (e.g. \"HGT_M\" variable), is used as the routing grid domain by WRF-Hydro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request help message from the script\n",
    "This is an example of the syntax for calling the `Create_Domain_Boundary_Shapefile.py` tool on the command line. By following the tool with `-h` or `--help`, we are able to call the help arguement which explains the purpose of the tool, shows the different arguements we can use for this tool, as well as the descriptions for each arguement. \n",
    "\n",
    "When the tool is run in the terminal, it is not necessary to use the exclamation point. In Jupyter Notebook, we can execute command-line syntax using \"!\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Create_Domain_Boundary_Shapefile\n",
    "\n",
    "# Execute script on the command-line, requesting tool help (parameter -h)\n",
    "! python Create_Domain_Boundary_Shapefile.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "You will see in the messages above that the tool provides a brief explanation of the expected input and output parameters. This tool requires a geogrid file as input (`-i`) and a directory to write the outputs into (`-o`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Execute the script using command-line syntax\n",
    "Now that we know what arguements are needed for this tool, we can enter those arguements and run the tool. For this script, we only need to specify the file path to the WPS geogrid file and an output folder to save the result. The result of this tool is a shapefile that shows the geographic boundary of the domain, as defined in the input geogrid file. \n",
    "\n",
    "When running this tool in Jupyter, we can use brackets around our variable names, and Jupyter will substitute the variable values when executing the syntax. However, when exeuting this script on the command line it is necessary to use the appropriate text. For the sake of repeatability, we also have Python print the full syntax for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print information to screen for reference\n",
    "print('Command to run:\\n')\n",
    "print('python Create_Domain_Boundary_Shapefile.py \\\\\\n\\t -i {0} \\\\\\n\\t -o {1}\\n'.format(in_geogrid, output_folder))\n",
    "\n",
    "# Run the script with required parameters\n",
    "! python Create_Domain_Boundary_Shapefile.py -i {in_geogrid} -o {output_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----\n",
    "The messages returned by the tool can be quite useful. You will see the coordinate system information printed to the screen and progress messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the domain boundary shapefile created in the above example\n",
    "\n",
    "Now that the domain boundary shapefile has been created, we want to see where the domain is relative to other features on a map. The next cell creates a map and adds the domain boundary as a layer. Use the map to explore the domain. A swipe feature allows the basemap to be changed between OpenStreetMap and satellite imagery. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import geopandas\n",
    "from ipyleaflet import Map, GeoJSON, ScaleControl, FullScreenControl, basemaps, SplitMapControl, basemap_to_tiles, LayersControl\n",
    "from jupyter_functions import create_map\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setup display items\n",
    "boundary_shp = os.path.join(output_folder,'geo_em.d01_boundary.shp')\n",
    "b_shp = geopandas.read_file(boundary_shp)\n",
    "b_shp = b_shp.to_crs(epsg=4326)\n",
    "\n",
    "# Export vector to GeoJSON\n",
    "b_json = os.path.join(output_folder, 'boundary.json')\n",
    "b_shp.to_file(b_json, driver='GeoJSON')\n",
    "\n",
    "# Read GeoJSON\n",
    "with open(b_json, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# Obtain vector center point\n",
    "x = b_shp.geometry.centroid.x\n",
    "y = b_shp.geometry.centroid.y\n",
    "map_center = y[0], x[0]\n",
    "\n",
    "# Instantiate map object\n",
    "m = Map(center=(41.50, -73.73), zoom=10, scroll_wheel_zoom=True)\n",
    "\n",
    "# Read GeoJSON\n",
    "with open(b_json, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Obtain vector center point\n",
    "x = b_shp.geometry.centroid.x\n",
    "y = b_shp.geometry.centroid.y\n",
    "map_center = y[0], x[0]\n",
    "\n",
    "# Instantiate map object\n",
    "m = create_map(map_center, 10)\n",
    "\n",
    "# Read GeoJSON\n",
    "geo_json = GeoJSON(data=data, name='Domain boundary')\n",
    "\n",
    "# Define basemaps to swipe between\n",
    "right_layer = basemap_to_tiles(basemap=basemaps.OpenStreetMap.Mapnik)\n",
    "left_layer = basemap_to_tiles(basemap=basemaps.Esri.WorldImagery)\n",
    "\n",
    "# Setup basemap swipe control\n",
    "control = SplitMapControl(left_layer=left_layer, right_layer=right_layer)\n",
    "m.add_control(control)\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "# Draw map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build GeoTiff raster from a WPS Geogrid file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tool `Build_GeoTiff_From_Geogrid_File.py` is a program to export variables from a WRF-Hydro input file (geogrid or Fulldom_hires) file to an output raster format, with all spatial and coordinate system metadata. If a 3-dimensional variable is selected, individual raster bands will be created in the output raster for each index in the 3rd dimension. If a 4-dimensional variable is selected, the first index in the 4th dimension will be selected and the variable will be treated as a 3-dimensional variable described above.\n",
    "\n",
    "This tool is handy for performing a quick vizualization using GIS or othe software to examine the contents of the WRF-Hydro input file and overlay these grids with other goespatial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool takes three input parameters: an input Geogrid or Fulldom_hires netCDF file (`-i`), a variable name (`-v`), and an output GeoTiff raster file (`-o`) that the tool will create. For this example, we will export the variable \"HGT_M\", or surface elevation in meters above sea level.\n",
    "\n",
    "#### Request help message from the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get script help information\n",
    "! python Build_GeoTiff_From_Geogrid_File.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----\n",
    "#### Execute the script using command-line syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the variable to export to raster\n",
    "in_var = \"HGT_M\"\n",
    "\n",
    "# Define the output raster file using variable name defined above\n",
    "out_file = os.path.join(output_folder, f'{in_var}.tif')\n",
    "\n",
    "# Print information to screen for reference\n",
    "print('Command to run:\\n')\n",
    "print('python Build_GeoTiff_From_Geogrid_File.py \\\\\\n\\t -i {0} \\\\\\n\\t -v {1} \\\\\\n\\t -o {2}\\n'.format(in_geogrid, in_var, out_file))\n",
    "\n",
    "# Run the script with required parameters\n",
    "! python Build_GeoTiff_From_Geogrid_File.py -i {in_geogrid} -v {in_var} -o {out_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View outputs\n",
    "Now that the tool has completed, we want to take a look at the output. We will create another interactive map and load the data as a layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import third-party visualization libraries\n",
    "import rasterio\n",
    "from matplotlib import pyplot\n",
    "from osgeo import gdal\n",
    "from ipyleaflet import ImageOverlay\n",
    "from jupyter_functions import cmap_options, show_raster_map\n",
    "\n",
    "# Create a map object from pre-build function\n",
    "m2 = create_map(map_center, 10)\n",
    "\n",
    "# Render the map\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use pre-built function to render the GeoTiff on the map, already warped to the map's coordinate system\n",
    "show_raster_map(out_file, m2, b_shp, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You will see the elevation grid applied to the map. This grid is 1km, so there is not much detail, but it is still useful to see if the topographic features are in the correct geographic locations according to the basemap. Also, there is no color-ramp for reference. This is a limitation of using the web browser over a GIS application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the hydrologic routing grids, aka the \"routing stack\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tool `Build_Routing_Stack.py` script is a program to build the full set of hydrologically-processed routing grids and additional data required by WRF-Hydro. This is the main utility for performing WRF-Hydro GIS pre-processing. The required inputs are related to the domain, routing grid resolution, and other options and parameter values. The output will be a routing stack zip file with WRF-Hydro domain and parameter files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Required Parameters:<br>\n",
    "&emsp;`-i` -WRF/WPS GEOGRID file (geo_em.d0*.nc)<br>\n",
    "&emsp;`-d` -High-resolution Elevation raster file (Esri GRID, GeoTIFF, VRT, etc.)<br>\n",
    "&emsp;`-R` -Regridding Factor – nesting relationship of routing:land surface model grid cells<br>\n",
    "&emsp;`-t` -Minimum basin area threshold (in routing grid cells)<br>\n",
    "&emsp;`-o` -Output ZIP File containing all script outputs<br>\n",
    "\n",
    "• Optional Parameters:<br>\n",
    "&emsp;`--CSV` -Station Locations location file (.csv)<br>\n",
    "&emsp;`-b` -Option to mask channel grids not contributing to provided station locations<br>\n",
    "&emsp;`-r` -Reach based (Muskingum / Muskingum-Cunge) routing option<br>\n",
    "&emsp;`-l` -Lake Polygons (polygon feature class or .shp)<br>\n",
    "&emsp;`-O` -OVROUGHRTFAC – Multiplier on Manning's roughness for overland flow. default=1.0<br>\n",
    "&emsp;`-T` -RETDEPRTFAC – Multiplier on maximum retention depth before flow is routed as overland flow. default=1.0<br>\n",
    "&emsp;-LKSATFAC – (script global variable) Multiplier on saturated hydraulic conductivity in lateral flow direction. default=1000.0<br>\n",
    "&emsp;`--starts` -Path to point shapefile or feature class containing channel initiation locations (overrides `-t` parameter)<br>\n",
    "&emsp;`--gw` -Path to polygon shapefile or feature class containing prescribed groundwater basin locations<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request help message from the script\n",
    "This tool has many different parameters and possible configurations. Using the command line, we can take a look at the different arguements that can be used, if they are required or optional, and what their default values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python Build_Routing_Stack.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Execute the script using command-line syntax\n",
    "We will begin by assigning file paths to variables, then use those variables in the command line tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Build_Routing_Stack\n",
    "\n",
    "# Define script input parameters using python variables\n",
    "in_geogrid = os.path.join(data_folder, 'geo_em.d01.nc')\n",
    "lakes = os.path.join(data_folder, 'lake_shapes', 'lakes.shp')\n",
    "csv = os.path.join(data_folder, 'croton_frxst_pts_FOSS.csv')\n",
    "in_dem = os.path.join(data_folder, 'NED_30m_Croton.tif')\n",
    "regrid_factor = 4\n",
    "routing_cells = 20\n",
    "out_zip = os.path.join(output_folder, 'croton_test.zip')\n",
    "\n",
    "# Print information to screen for reference\n",
    "print('Command to run:\\n')\n",
    "print('python Build_Routing_Stack.py \\\\\\n\\t -i {0} \\\\\\n\\t -l {1} \\\\\\n\\t --CSV {2} \\\\\\n\\t -d {3} \\\\\\n\\t -R {4} \\\\\\n\\t -t {5} \\\\\\n\\t -o {6}\\n'.format(in_geogrid, lakes, csv, in_dem, regrid_factor, routing_cells, out_zip))\n",
    "\n",
    "# Run the script with required parameters\n",
    "! python Build_Routing_Stack.py -i {in_geogrid} -l {lakes} --CSV {csv} -d {in_dem} -R {regrid_factor} -t {routing_cells} -o {out_zip}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Understanding the outputs\n",
    "\n",
    "The `Build_Routing_Stack.py` script creates a Zip archive of output files according to the options provided to the tool. There will be at least four netCDF files; one spatial metadata file describing the LDAS grid (‘GEOGRID_LDASOUT_Spatial_Metadata.nc), one 2D file describing the routing grid (‘Fulldom_hires.nc’), a 2D groundwater basin file (‘GWBASINS.nc’), and a 1D groundwater basin parameter file (‘GWBUCKPARM.nc’). The ‘Fulldom_hires.nc’ file will contain between 13 and 14 2-dimensional (gridded) netCDF variables. The output Zip file may additionally include shapefiles (.shp and accompanying files) describing the geometry of modeled lakes or the vector stream network, and netCDF 1-dimensional parameter tables (.nc) describing lake parameters (‘LAKEPARM.nc’) or the stream network (‘Route_Link.nc’). All variables in the ‘Fulldom_hires.nc’ file will have the same grid dimensions. The x-dimension is always ‘x’ and the y-dimension always ‘y’.  Below is an alphabetically sorted list of gridded variables that are created by the `Build_Routing_Stack.py` tool, and Table 5 contains descriptions of each grid.\n",
    "\n",
    "Fulldom_hires.nc file:\n",
    "  + CHANNELGRID - The channel grid. Channel pixels = 0, non-channel pixels = -9999. If the `-b` option is set to TRUE, the output will be masked to the gaged basins provided, where non-gaged channels are given a value of ‘-1’. If lake routing is activated, lake outflow points will be identified by the lake ID value.\n",
    "  + FLOWACC – Flow accumulation grid. This grid gives the number of contributing cells for each cell in the domain. This grid is provided for convenience and is not read by WRF-Hydro.\n",
    "  + FLOWDIRECTION – Flow direction grid. This grid gives the direction of flow using the D8 algorithm between each cell and the steepest downslope neighbor according to Jenson and Domingue (1988). The result is an integer grid with values ranging from 1 to 128.\n",
    "  + frxst_pts – Gage location grid. If a forecast point CSV file is provided, the grid will have a cell identified at the location of each forecast point (gage) in the gage CSV file. If no input CSV gage location file is provided, this grid will be uniform with values of ‘-9999’. Gage pixels are numbered in the same way as the ‘basn_msk’ grid. NoData cells are given a value of ‘-9999’.\n",
    "  + basn_msk – Forecast basins grid. If a CSV gage location file is provided, catchments are delineated from a point that is up to 3 pixels downstream of the gage coordinates. This distance can be modified by altering the ‘walker’ global variable in the ‘wrfhydro_functions.py’ script. If masking of the ‘CHANNELGRID’ is selected, this layer is the mask. Basins are numbered according to the values in the ‘FID’ field of the input gage CSV file. If no gage location file is provided, this grid will be uniform with values of ‘-9999’.\n",
    "  + LAKEGRID – The lake grid. If a lake polygon shapefile is provided to the `-l` parameter, this grid will contain ID values for each lake that can be resolved on the routing grid. Otherwise, this grid will be uniform with values of -9999.\n",
    "  + landuse – This is the same data as the ‘LU_INDEX’ variable in the GEOGRID file, but resampled using Nearest Neighbor assignment to the resolution of the routing grid. This grid is provided for convenience and is not read by WRF-Hydro.\n",
    "  + LATITUDE – Grid of the latitude at the center of each grid cell, in a geographic coordinate system (WGS84).\n",
    "  + LINKID – The channel ID grid. This grid provides a unique integer identifier for each channel segment that is defined in the ‘link’ variable of the ‘Route_Link.nc’ file and the ‘STRM_VAL’ field in the ‘streams.shp’ shapefile. The ‘LINKID’ grid will only be created if the option `-r` is TRUE.\n",
    "  + LONGITUDE – Grid of longitude value at the center of each grid cell, in a geographic coordinate system (WGS84).\n",
    "  + OVROUGHRTFAC – OVROUGHRTFAC parameter. Currently set to a default of 1.0. This default value may be changed by providing an alternate value to the `-O` parameter.\n",
    "  + RETDEPRTFAC – RETDEPRTFAC (retention depth multiplier) parameter. Currently set to a default of 1.0. This default value may be changed by providing an alternate value `-T` parameter.\n",
    "  + STREAMORDER – Stream order grid, calculated using the Strahler method (Strahler 1957).\n",
    "  + TOPOGRAPHY – Elevation grid. The units of elevation are the same as the input elevation raster dataset (`-d INDEM`), which should be specified in meters (m) above sea level (ASL). This grid is derived from the elevation values in the input elevation raster, but has been resampled to the routing grid resolution, and pit-filled according to the method described in Planchon and Darboux (2002).\n",
    "\n",
    "Other files:\n",
    "  + GEOGRID_LDASOUT_Spatial_Metadata.nc  - This is a CF-netCDF format file that provides the spatial metadata associated with the GEOGRID variables. By default, no 2-dimensional grids are written to the file. This file may be used by WRF-Hydro for appending geospatial metadata to the land surface model output, if necessary.\n",
    "  + GWBASINS.nc - This is a 2D netCDF file of the location of groundwater basins, regridded to the LSM grid resolution. NoData cells are given a value of ‘-9999’. This file is by default created using the ‘FullDom LINKID local basins’ method of defining groundwater basins.\n",
    "  + LAKEPARM.nc – Lake parameter table. This 1D netCDF format file is created if a lake shapefile is provided as input to the `-l` parameter. The table will contain a record for each lake feature in the + Fulldom_hires.nc ‘LAKEGRID’ variable, and contain derived and default parameters for each lake.\n",
    "  + Route_Link.nc – The reach-based routing parameter file. This 1D netCDF format file is created if the `-r` parameter is TRUE. The file contains a record for each stream segment. The stream segments in this table are also identified by the unique ‘LINKID’ values in the ‘LINKID’ variable in the ‘Fulldom_hires.nc’ file, and values in the ‘STRM_VAL’ field of the output ‘streams.shp’ shapefile. This table contains derived and default stream segment parameters that are calculated based on the vector stream network and topology in the ‘streams.shp’ shapefile.\n",
    "  + streams.* (ancillary) - Streams shapefile, containing one feature for each stream segment in the domain. This file is meant to accompany the ‘Route_Link.nc’ reach-based routing parameter file and Fulldom_hires.nc ‘LINKID’ variable. The ‘streams’ shapefile is only created when the option `-l` is used. The ‘STRM_VAL’ field is the unique identifier for each stream segment, and corresponds to the ‘link’ variable of the ‘Route_Link.nc’ file and the ‘LINKID’ variable in the ‘Fulldom_hires.nc’ file. The geometry of the stream segments in this shapefile informs many of the parameters in the ‘Route_Link.nc’ file.\n",
    "  + lakes.* (ancillary) - Lakes shapefile, containing one feature for each reservoir in the simulation domain. This file is meant to accopmany the 'LAKEPARM.nc' reservoir parameter file. If `-r TRUE` is used, then Fulldom_hires.nc 'LAKEID' variable will contain -9999 values only. The geometry of reservoir objects informs many of the parameters in 'LAKEPARM.nc' file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Examine outputs of GIS pre-processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tool `Examine_Outputs_of_GIS_Preprocessor.py` script is a tool that takes the output ZIP file generated using the Process Geogrid script (executed above) and creates a raster from each 2D variable in each WRF-Hydro input netCDF file. In addition, other data will be extracted such as any shapefiles, 1D netCDF tables, etc. The input to the tool should be a .zip file that was created using the WRF Hydro pre-processing tools. The tool will create the output folder if it does not already exist, and write all results to that location.\n",
    "\n",
    "#### Request help message from the script\n",
    "This tool has a single input and single output parameter. Using the command line, we can take a look at the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! python Examine_Outputs_of_GIS_Preprocessor.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Execute the script using command-line syntax\n",
    "We will define the output directory for the tool to create, then use defined variables to execute the command line tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define output directory to store GeoTiff output of all routing stack grids\n",
    "raster_outputs = os.path.join(output_folder, \"Raster_Outputs\")\n",
    "\n",
    "# Print information to screen for reference\n",
    "print('Command to run:\\n')\n",
    "print('python Examine_Outputs_of_GIS_Preprocessor.py \\\\\\n\\t -i {0} \\\\\\n\\t -o {1}\\n'.format(out_zip, raster_outputs))\n",
    "\n",
    "# Run the script with required parameters\n",
    "! python Examine_Outputs_of_GIS_Preprocessor.py -i {out_zip} -o {raster_outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Vizualize the output grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to take a look at some of the output rasters. Below, we utilize a Jupyter widget to choose each raster from a drop down menu. Each of the 2D variables in Fulldom_hires.nc (the routing grid netCDF file) will be displayed as a rectangular grid. Take a look at some of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "def see_raster(x):\n",
    "    src = rasterio.open(os.path.join(raster_outputs, f\"{x}.tif\"))\n",
    "    cmap, norm = cmap_options(x)\n",
    "    if x in ['TOPOGRAPHY']:\n",
    "        pyplot.imshow(src.read(1), cmap=cmap,  aspect='auto', norm=norm, interpolation='nearest', vmin=0)\n",
    "    else:\n",
    "        pyplot.imshow(src.read(1), cmap=cmap,  aspect='auto', norm=norm, interpolation='nearest')\n",
    "    cbar = pyplot.colorbar()\n",
    "    \n",
    "    # Keep the automatic aspect while scaling the image up in size\n",
    "    fig = pyplot.gcf()\n",
    "    w, h = fig.get_size_inches()\n",
    "    fig.set_size_inches(w * 1.75, h * 1.75)\n",
    "    \n",
    "    # Show image\n",
    "    pyplot.show()\n",
    "\n",
    "in_raster = widgets.Dropdown(\n",
    "    options=[('Basin', 'BASIN'), ('Basin mask', 'basn_msk'), ('Channel grid', 'CHANNELGRID'), ('Flow accumulation', 'FLOWACC'),\n",
    "            ('Flow direction', 'FLOWDIRECTION'), ('Forecast points', 'frxst_pts'), ('Lake grid', 'LAKEGRID'),\n",
    "            ('Land use', 'landuse'), ('Latitude', 'LATITUDE'), ('LKSATFAC', 'LKSATFAC'), ('Longitude', 'LONGITUDE'),\n",
    "            ('OVROUGHRTFAC', 'OVROUGHRTFAC'), ('RETDEPRTFAC', 'RETDEPRTFAC'), ('Stream order', 'STREAMORDER'),\n",
    "            ('Topography', 'TOPOGRAPHY')],\n",
    "    value='FLOWACC',\n",
    "    description='Variable:')\n",
    "\n",
    "interact(see_raster, x=in_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the raster data projected onto a map. Use the dropdown widget below the map to add rasters as layers to the map. Use the menu in the top right corner of the map to turn layers on and off. Behind the scenes, each model grid is being reprojected to Web Mercator for overlay on a WMS basemap for some interactivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a map object from pre-build function\n",
    "m3 = create_map(map_center, 10)\n",
    "\n",
    "# Render the map\n",
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    r_path = os.path.join(raster_outputs, f\"{x}.tif\")\n",
    "    show_raster_map(r_path, m3, b_shp, output_folder)\n",
    "\n",
    "in_raster = widgets.Dropdown(\n",
    "    options=[('Basin', 'BASIN'), ('Flow accumulation', 'FLOWACC'), ('Flow direction', 'FLOWDIRECTION'), \n",
    "             ('Land use', 'landuse'), ('Stream order', 'STREAMORDER'), ('Topography', 'TOPOGRAPHY')],\n",
    "    value='FLOWDIRECTION',\n",
    "    description='Variable:',\n",
    ")\n",
    "interact(f, x=in_raster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
