{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an iES experiment\n",
    "\n",
    "The iterative ensemble smoother as implemented in PEST++ is an ensemble-based version of the Gauss-Levenberg-Marquardt (GLM), gradient-based regression technique for minimizing a weighted sum-of-squared residuals objective function for history matching. This approach is similar to an Ensemble Kalman Filter in which all the data are assimilated in a single batch.\n",
    "\n",
    "We adopt the following steps for performing history matching using iES. \n",
    "\n",
    "<img src=\"./images/iES_workflow.png\" width=\"500\"/>\n",
    "\n",
    "In the previous lesson we performed the prior MC run, and in this lesson we will go through the rest of the steps shown in the flowchart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyemu\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pytsproc import filters, series_metrics\n",
    "plt.rcParams['font.size']=12\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1. Define the working directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the single model run PEST++ host directory \n",
    "singledir = Path('/home/docker/wrf-hydro-training/output/lesson4/host')\n",
    "\n",
    "# Define the path to the prior MC PEST++ host directory \n",
    "priordir = Path('/home/docker/wrf-hydro-training/output/lesson5/host') \n",
    "\n",
    "# Define where the iES work directory would be\n",
    "iesdir = Path('/home/docker/wrf-hydro-training/output/lesson6/iES_Run') \n",
    "\n",
    "# Define where to save plots generated in this notebook\n",
    "plotdir = Path('/home/docker/wrf-hydro-training/output/lesson6/plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(plotdir):\n",
    "    plotdir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2.  Define the calibration, validation and spin up period.** \n",
    "Below is a short description of \n",
    "* burn_in: this is the time period that the model simulations will be discarded. We usually define a period where the model is run to adjust to the change of the parameters and avoid model instability, this period is not used in the calibration or validation of the model. In a real experiment, this could be a year. \n",
    "* calibration: this is the period used for parameter estimation.\n",
    "* validation: the independent period used to verify the model performance after performing history matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_start_date = '2018-08-01'\n",
    "valid_start_date = '2018-08-02'\n",
    "calib_start_date = '2018-08-10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3. Read in the PESTPP control file from the single model run**\n",
    "\n",
    "We could read the information of a given model run using PyEMU library, and make adjustment and modifications and create a new model run. \n",
    "Here we are attempting to follow the steps in flowchart in blue using the single model run. \n",
    "Let us read the experiment, look at the parameters and the observation used in parameter estimation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(str(singledir / 'wrfpst.pst'), resfile=str(singledir / 'wrfpst.base.rei'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters used in the history matching experiment is saved in the `parameter_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation dataset used in the history matching is saved in the `observation_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could display different components of the phi calculation, here we had only one obsevration category called `streamflow`. In this lesson we will define more groups and weigh them differently to form the objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind='phi_pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step4. Categorize the observation**\n",
    "\n",
    "Let's start with defining the burnin and validation period first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the observation data \n",
    "obs = pst.observation_data.copy()\n",
    "\n",
    "obs.loc[obs.obsval==-9999, 'obsval'] = np.nan\n",
    "\n",
    "def parsename(cn):\n",
    "    '''\n",
    "    parse the dates from the WRF_hydro obs names\n",
    "    '''\n",
    "    tmp = cn.replace('obs_','')\n",
    "    return dt.strptime(tmp, '%Y%m%d_%H0000')\n",
    "\n",
    "# get the time from the name of the observation obs_YYYYmmdd_hhMMSS\n",
    "obs['dtime'] = [np.nan] + [parsename(i) for i in obs.iloc[1:].index]\n",
    "\n",
    "# trim off the burn-in period\n",
    "obs.loc[obs.dtime<valid_start_date, 'obgnme'] = 'burn_in'\n",
    "\n",
    "# label the validation period\n",
    "obs.loc[(obs.dtime >= valid_start_date) & (obs.dtime < calib_start_date), 'obgnme'] = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy over the updated obsgroups to the original\n",
    "pst.observation_data.obgnme = obs.obgnme.values\n",
    "\n",
    "obgnames = obs.obgnme.copy()\n",
    "\n",
    "obgnames.loc['kge'] = 'kge'\n",
    "print(obgnames.unique())\n",
    "\n",
    "obs['discharge'] = obs.obsval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # set index to datetime\n",
    "obs.set_index('dtime', drop=False, inplace=True)\n",
    "\n",
    "# plot the full period of simulation\n",
    "ax = obs.discharge[1:].plot(figsize=(14,4))\n",
    "ax.axvline('2018-08-02', c='orange', alpha=.4);\n",
    "ax.axvline('2018-08-10', c='green', alpha=.4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For next analysis, trim off kge and burn in and validation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trim off the observation and only keep the calibration period\n",
    "obs = obs.iloc[1:].loc[obs.dtime>= calib_start_date]\n",
    "\n",
    "# Finding the NaN streamflows\n",
    "print(obs.loc[obs.discharge.isnull()])\n",
    "\n",
    "# fill in the nan discharge values with linear interpolatoin\n",
    "obs['discharge']=obs.discharge.interpolate()\n",
    "\n",
    "# flip back the NaN obs values to -9999\n",
    "obs.loc[obs.obsval.isnull(), 'obsval'] = -9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles\n",
    "\n",
    "In this step, we will define the streamflow quantiles and apply and categorize the flow based on which quantiles if falls into. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of quantiles\n",
    "quantiles=4\n",
    "\n",
    "quantile_vals = [obs.discharge.quantile(((i+1)/quantiles)) for i in range(quantiles)]\n",
    "\n",
    "quantile_vals\n",
    "\n",
    "#identify the locations of the quantiles\n",
    "obs['quantile_grp'] = np.nan\n",
    "for i,q_current in zip(range(1,quantiles+1),quantile_vals):\n",
    "    if i==1:\n",
    "        obs.loc[obs.discharge<=q_current, 'quantile_grp'] = 'q1'\n",
    "    else:\n",
    "        obs.loc[(obs.discharge <= q_current) & (obs.discharge>quantile_vals[i-2]), 'quantile_grp'] = f'q{i}'\n",
    "        \n",
    "\n",
    "assert len(obs.loc[obs.quantile_grp.isnull()]) == 0\n",
    "\n",
    "obs.quantile_grp.unique()\n",
    "\n",
    "for cn,cg in obs.groupby('quantile_grp'):\n",
    "    print(cn, len(cg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event based weighting\n",
    "\n",
    "Next, we will define events using the function `hydro_events`, this function provided the start and end date of events as well as peak time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qhe = series_metrics.hydro_events(obs,  wlen=50, prominence=25, height=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ax = obs.discharge.plot(figsize=(14,4))\n",
    " [ax.axvline(i, c='orange', alpha=.4) for i in Qhe[1]['event_starts']];\n",
    " [ax.axvline(i, c='green', alpha=.4) for i in Qhe[1]['event_ends']];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qhe[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the new group naming \n",
    "obs.obgnme = obs.quantile_grp\n",
    "for st, en in zip(Qhe[1]['event_starts'], Qhe[1]['event_ends']):\n",
    "    obs.loc[(obs.index>=st) & (obs.index<=en), 'obgnme'] = 'event'\n",
    "obs.loc[obs.obgnme=='event']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now bring the new observation group names back to `pst.observation_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pst.observation_data.loc[obs.obsnme, 'obgnme'] = obs.obgnme.values\n",
    "\n",
    "# there is only the KGE field which has the group name of the streamflow\n",
    "pst.observation_data.loc[pst.observation_data.obgnme=='streamflow', 'obgnme'] = 'kge'\n",
    "pst.observation_data.loc[pst.observation_data['obgnme'] == 'kge', 'weight'] = 0\n",
    "\n",
    "pst.observation_data.loc[pst.observation_data.index.isin(obs.obsnme), 'obgnme'] = obs.obgnme.values\n",
    "\n",
    "pst.observation_data.loc[pst.observation_data['obsval'] == -9999, 'obgnme'] = 'burn_in'\n",
    "pst.observation_data.loc[pst.observation_data['obsval'] == -9999, 'weight'] = 0\n",
    "pst.observation_data.loc[pst.observation_data['obgnme'] == 'burn_in', 'weight'] = 0\n",
    "pst.observation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let us check the contribution of each category to the phi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind='phi_pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5. Reweight observations based on the 10% CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[pst.observation_data.obgnme != 'kge' , 'weight'] = \\\n",
    "    10 / pst.observation_data.loc[pst.observation_data.obgnme != 'kge' , 'obsval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let us set the weights for the burn in and validation period to 0 also so they do not contibute to the calibration of the phi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[pst.observation_data['obsval'] == -9999, 'obgnme'] = 'burn_in'\n",
    "pst.observation_data.loc[pst.observation_data['obsval'] == -9999, 'weight'] = 0\n",
    "\n",
    "pst.observation_data.loc[pst.observation_data.obgnme == 'burn_in' , 'weight'] = 0 \n",
    "pst.observation_data.loc[pst.observation_data.obgnme == 'validation' , 'weight'] = 0 \n",
    "\n",
    "pst.res['weight'] = pst.observation_data.weight.values # have to trick the residuals to know about new obsgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[pst.observation_data.obgnme=='streamflow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind='phi_pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6. Provide weighting for each category**\n",
    "\n",
    "The objective function for iES is the weighted sum of squared errors. While this makes up a single quantity, the weights–assigned to each observation–are used to balance the contribution of various observation categories (e.g. streamflows of different flow regimes, peaks, recession periods, and others) to the objective function. This allows tuning the history matching process to estimate parameters appropriate for a specific output category. In this training, we are targeting a superior performance during the events and therefore, providing half of the weights to the `event` category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there were no 0 flow values which would result in infinite weights\n",
    "assert np.unique(np.isinf(pst.observation_data.weight.values)) == np.array([False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_portions = {'burn_in': 0.0,\n",
    " 'validation':0,\n",
    " 'event': 0.5,\n",
    " 'kge': 0.0,\n",
    " 'q1': 0.1,\n",
    " 'q2': 0.1,\n",
    " 'q3': 0.1,\n",
    " 'q4': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_portions = {k:v*pst.nnz_obs for k,v in \n",
    "                new_portions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.res['group'] = pst.observation_data.obgnme.values # have to trick the residuals to know about new obsgp\n",
    "pst.res['weight'] = pst.observation_data.weight.values # have to trick the residuals to know about new obsgp\n",
    "pst.adjust_weights(obsgrp_dict=new_portions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind='phi_pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 7. Recalculate the objective function (phi) with new weights to perform rejection sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obens = pyemu.ObservationEnsemble.from_csv(pst, str(priordir / 'wrfpst.0.obs.csv'),\n",
    "                                           index_col=0, dtype={'real_name':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = obens.phi_vector\n",
    "print(len(phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No noise\n",
    "phi.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 7. Perform rejection sampling Based on Prior MC runs**\n",
    "\n",
    "To perform rejection sampling we would look into the objective function calculated using the new weighting, and define a cutoff to remove the outliers. In this small exmaple, we probably do not benefit from rejection sampling. This is only for training purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phicutoff = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(phi))\n",
    "phi = phi.loc[phi<phicutoff]\n",
    "print(len(phi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals_to_keep = phi.index.values\n",
    "reals_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_pars = pd.read_csv(priordir / 'wrfpst.0.par.csv', index_col=0, dtype={'real_name':str})\n",
    "pp = prior_pars.loc[reals_to_keep]\n",
    "pp.index = [str(i) for i in range(len(pp)-1)] + ['base']\n",
    "pp.to_csv(\n",
    "            priordir/'wrfpst.starting_pars.csv')\n",
    "oe = obens._df.loc[reals_to_keep].copy()\n",
    "oe.index = pp.index\n",
    "oe.to_csv(\n",
    "            priordir/'wrfpst.starting_obs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 8. Create iES run directory**\n",
    "Let us first Delete iES folder if it is already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(Path(iesdir)):\n",
    "    shutil.rmtree(iesdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the run directory similar by copying the single model run directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ~/wrf-hydro-training/output/lesson4/Single_Model_Run/ ~/wrf-hydro-training/output/lesson6/iES_Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could make the modification to the PEST++ control files and overwrite the files in the iES run directly. Let us start with preparing the new starting observation and parameter files for the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_pars = pd.read_csv(priordir / 'wrfpst.0.par.csv', index_col= 0, dtype={'real_name':str})\n",
    "pp = prior_pars.loc[reals_to_keep]\n",
    "pp.index = [str(i) for i in range(len(pp)-1)] + ['base']\n",
    "pp.to_csv(iesdir/'wrfpst.starting_pars.csv')\n",
    "oo = obens._df.loc[reals_to_keep].copy()\n",
    "oo.index = pp.index\n",
    "oo.to_csv(iesdir/'wrfpst.starting_obs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User specified observation file with added noise\n",
    "The iES algorithm is predicated on the assumption that the ensemble of observation measurement values is corrupted by noise. \n",
    "However, PEST++ also includes an option to ignore noise in the observations \n",
    "(ies_no_noise = true, and no provided observation ensemble). \n",
    "If the noise is ignored, the ensemble of observations will be all identical members. \n",
    "Next available option is to generate the noise using the existing framework in PEST++ \n",
    "(ies_no_noise = false, and no provided observation ensemble). \n",
    "In this case, error in observations are additive noise sampled from an assumed pdf of observation error. \n",
    "The time series generated using this approach are usually not smooth, since the additive noise could be a positive \n",
    "value at one time step and reverse sign in the next time step. \n",
    "Ideally, we would like to have smooth hydrographs, in particular to preserve the diurnal cycles properly in the model. \n",
    "Alternative method is to supply an external text file containing observation realizations with added noise. \n",
    "Using this feature, we could provide the observation ensemble with temporally auto-correlated additive noise. \n",
    "Here, we have created an observation file with the added noise which will be used instead of the single observation time series. Note the observation was created for a case with 300 ensembles, however, due to compute limitations here, we are only using a subset of those ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_noise_ens = pd.read_csv('/home/docker/wrf-hydro-training/example_case/OBS/obs_noise_01473000_300ens_201808.csv', \n",
    "                            index_col = 'real_name', dtype={'real_name':str})\n",
    "one = obs_noise_ens.loc[reals_to_keep].copy()\n",
    "one.index=pp.index\n",
    "one.to_csv(iesdir/'wrfpst.starting_obs+noise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_noise_ens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the PEST++ Control File\n",
    "Last but not the least, we want to modify the entries of the PEST++ control file and set some problem specific PESTPP-IES settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reals_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax=2\n",
    "pst.pestpp_options[\"ies_num_reals\"] = len(reals_to_keep)\n",
    "pst.pestpp_options[\"overdue_giveup_minutes\"] = 200\n",
    "pst.pestpp_options[\"ies_no_noise\"] = 'false'\n",
    "pst.pestpp_options[\"ies_observation_ensemble\"] = 'wrfpst.starting_obs+noise.csv'\n",
    "pst.pestpp_options[\"ies_restart_observation_ensemble\"] = 'wrfpst.starting_obs.csv'\n",
    "pst.pestpp_options[\"ies_parameter_ensemble\"] = 'wrfpst.starting_pars.csv'\n",
    "\n",
    "pst.write(iesdir/'wrfpst.pst', version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 9. Running PEST++ with WRF-Hydro**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_path (str, optional) – the relative path to where pest(++) should be run from within the worker_dir, defaults to the uppermost level of the worker dir. \n",
    "\n",
    "pyemu.utils.os_utils.start_workers(worker_dir = \"/home/docker/wrf-hydro-training/output/lesson6/iES_Run\", \n",
    "                                   exe_rel_path = \"pestpp-ies\", \n",
    "                                   pst_rel_path = \"wrfpst.pst\", \n",
    "                                   num_workers=8, \n",
    "                                   worker_root='/home/docker/wrf-hydro-training/output/lesson6/',\n",
    "                                   master_dir = \"/home/docker/wrf-hydro-training/output/lesson6/host\",\n",
    "                                   port=4004, \n",
    "                                   verbose = True, \n",
    "                                   cleanup = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 10. Let check the run directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "ls  /home/docker/wrf-hydro-training/output/lesson6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "ls  /home/docker/wrf-hydro-training/output/lesson5/host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The successful finish message of PEST++ could be found in the wrfpst.rmr file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat  /home/docker/wrf-hydro-training/output/lesson5/host/wrfpst.rec | tail -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the content of the workder folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "ls  /home/docker/wrf-hydro-training/output/lesson4/worker_0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could continue to the next lesson and verify the results of the history matching exercise using the iES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
